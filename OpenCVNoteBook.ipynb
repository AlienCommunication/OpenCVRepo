{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image using imread, and then path of the image \n",
    "\n",
    "loadImage = cv2.imread(\"Screenshot 2020-03-31 at 12.45.55 AM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 596, 3)\n"
     ]
    }
   ],
   "source": [
    " print(loadImage.shape) #To check the dimensions  of the image, Height, width, channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Image 1/2 of its original size\n",
    "\n",
    "# fy=0.5, fx=0.5 are basically functions used to scale down the images \n",
    "decreased_Size = cv2.resize(loadImage, None, fx =0.5, fy= 0.5)\n",
    "cv2.imshow(\"Scaled_Image\", decreased_Size)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Making an image 1.5 times bigger than the actual size. \n",
    "\n",
    "increased_Size=  cv2.resize(loadImage, None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Scaled_Up_Image\", increased_Size)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "#Resizing the images by using dimensions\n",
    "\n",
    "dimesions_size=  cv2.resize(loadImage, (700, 150),  interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Scaled_Up_by_Dimensions of Image\", dimesions_size)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_image = cv2.pyrDown(loadImage)\n",
    "larger_image = cv2.pyrUp(smaller_image)\n",
    "cv2.imshow(\"Original Image\", loadImage)\n",
    "cv2.imshow(\"Smaller Image\", smaller_image)\n",
    "cv2.imshow(\"Larger Image\", larger_image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding various lines, shapes to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding lines\n",
    "# (1,1 ) is nothing but co-ordinates positions of the line\n",
    "# (250,250) represents ending position of the line\n",
    "# (100, 250, 0)  It represents the color of the line \"RGB\"\n",
    "# 4 represents the thickness of the line\n",
    "cv2.line(loadImage, (1,1), (250, 250), (100,250,0), 4)\n",
    "cv2.imshow(\"Blue Line\", loadImage)\n",
    "cv2.waitKey(0) #Zero because I want to keep this image open until i do not click on close-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add circle to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding lines\n",
    "# (200,200 ) is nothing but Center-ordinates of the circle\n",
    "# 75 represents radius of the circle\n",
    "# (250,0, 0)  It represents the color of the line \"RGB\"\n",
    "# -1 represents the Solid circle\n",
    "cv2.circle(loadImage, (250, 250), 75, (250,0,0), -1)\n",
    "cv2.imshow(\"Blue Line\", loadImage)\n",
    "cv2.waitKey(0) #Zero because I want to keep this image open until i do not click on close-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding text to our Image by using PutText function in OpenCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation of arguements :\n",
    "PutText is the function used in OpenCV, It takes arguements like\n",
    "Image path, Text you would like to write on the image, Co-ordinates basically where you want to show the image It has to be decided by you, Font type used in OpenCV, Font size and then thickness of the color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(loadImage, \"Writing sentence on this image\" , (10, 100), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 2, (100,250, 0))\n",
    "\n",
    "cv2.imshow(\"Writing anyting\", loadImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllTheWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423 596\n",
      "=========\n",
      "[[  1.     0.   105.75]\n",
      " [  0.     1.   149.  ]]\n"
     ]
    }
   ],
   "source": [
    "#extract height and width of an Image\n",
    "\n",
    "height, width = loadImage.shape[:2]\n",
    "\n",
    "print(height, width)\n",
    "\n",
    "print(\"=========\")\n",
    "\n",
    "\n",
    "#translating Image height and width of an image to 1/4\n",
    "\n",
    "height_fourth, width_fourth = height/4, width/4\n",
    "\n",
    "# Translation Matrix T\n",
    "\n",
    "T = np.float32([[1, 0, height_fourth], [0,1, width_fourth]])\n",
    "\n",
    "# Printing the value of translation matrix T\n",
    "\n",
    "print(T)\n",
    "\n",
    "\n",
    "#Using waraffine to transform an image  using the translation matrix, T\n",
    "\n",
    "translation = cv2.warpAffine(loadImage, T , (width, height))\n",
    "\n",
    "# Showing the image output\n",
    "\n",
    "\n",
    "cv2.imshow(\"Translated Image\", translation)\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Croping or cutting the desired image\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It helps in keeping only the desired or requirred parts of an Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width= loadImage.shape[:2]\n",
    "#Extracts pixels co-ordinates(Starting from Top left)\n",
    "\n",
    "start_row, start_col = int(height *.20), int(width *.20)\n",
    "\n",
    "# Extract pixels co-ordinates (Ending to bottom right)\n",
    "\n",
    "end_row, end_col = int(height * .80), int(width * .80)\n",
    "\n",
    "#Using Indexing method to crop the desired rectangle area\n",
    "\n",
    "cropped_image = loadImage[start_row:end_row, start_col:end_col]\n",
    "\n",
    "#Displaying Original Image and Cropped Image\n",
    "\n",
    "cv2.imshow(\"Original Image\", loadImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Cropped Image\", cropped_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotating the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract height and width of the image\n",
    "height, width = loadImage.shape[:2]\n",
    "\n",
    "# Divide by four to rotate the image around its centre\n",
    "rotation_mat_R = cv2.getRotationMatrix2D((width/2, height/2), 45, .5)\n",
    "\n",
    "rotated_image_output = cv2.warpAffine(loadImage, rotation_mat_R, (width, height))\n",
    "\n",
    "cv2.imshow('Rotated Image', rotated_image_output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the Image\n",
    "\n",
    "# Flipping image horizontally.\n",
    "flipped_img = cv2.flip(loadImage, 1)\n",
    "cv2.imshow('Horizontal Flip', flipped_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening the Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shapening kernel\n",
    "sharpening_filter = np.array([[-1,-1,-1],\n",
    "[-1,9,-1],\n",
    "[-1,-1,-1]])\n",
    "\n",
    "# Applying kernel(s) to the input image to get the sharpened image\n",
    "sharpened_image = cv2.filter2D(loadImage, -1, sharpening_filter)\n",
    "\n",
    "cv2.imshow('Sharpened Image', sharpened_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image threshold and binarization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How can we create a binary image from a grayscale image or full color image so that We can seperate objects from foreground picture to background picture to add in Image processing\n",
    "\n",
    "Note: Threshold functions accepts only Grayscale image hence make sure to convert your COlor image into grayscale before you perform the Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Values below 127 set to 0 (black), rest everything above set to 255 (white)\n",
    "ret,threshold_1 = cv2.threshold(loadImage, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', threshold_1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 set to 255 (white), rest everything above set to 0 (black). Opposite of above\n",
    "ret,threshold_2 = cv2.threshold(loadImage, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Threshold Binary Inverse', threshold_2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values above 127 are truncated i.e shades with range 128 to 255 are set as 127.\n",
    "ret,threshold_3 = cv2.threshold(loadImage, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('Threshold Trunc', threshold_3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 set to 0, values above 127 remain unchanged\n",
    "ret,threshold_4 = cv2.threshold(loadImage, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('Threshold To Zero', threshold_4)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 remain unchanged, values above 127 goes to 0\n",
    "ret,threshold_5 = cv2.threshold(loadImage, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('Threshold To Zero Inv', threshold_5)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image =-=-=-=-=-=-=-=-=-=\n",
    "input_image3 = cv2.imread('Screenshot 2020-03-31 at 12.45.55 AM.png', 0)\n",
    "cv2.imshow(\"Original Image\", input_image3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 set to 0 (black), rest everything above set to 255 (white)\n",
    "ret,threshold_1 = cv2.threshold(input_image3, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Threshold Binary\", threshold_1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Blur the image\n",
    "blurred_image = cv2.GaussianBlur(input_image3, (3, 3), 0)\n",
    "\n",
    "# Using adaptiveThreshold\n",
    "adp_thresholding = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "cv2.THRESH_BINARY, 3, 5)\n",
    "cv2.imshow(\"Adaptive Thresholding\", adp_thresholding)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
